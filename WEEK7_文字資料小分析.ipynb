{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiroqPre88+P66eRmZeIqy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alayuala/114-1PL.repo/blob/main/WEEK7_%E6%96%87%E5%AD%97%E8%B3%87%E6%96%99%E5%B0%8F%E5%88%86%E6%9E%90.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **文字資料小分析（報告草稿/問卷開放題）（作業四）**  \n",
        "* 目標：從 Sheet 讀開放式回答 → 做詞數與關鍵字計數 → 輸出前 N 熱詞 → 回寫統計表。  \n",
        "* AI 點子：請模型產出 5 句洞察摘要 + 一段 120 字結論。  \n"
      ],
      "metadata": {
        "id": "n8tr6INakL5U"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40ed29ac"
      },
      "source": [
        "# 安裝必要的 Python 套件\n",
        "# 這邊列出了我們這個專案會用到的所有套件\n",
        "# gspread: 用來操作 Google Sheets\n",
        "# gspread_dataframe: 方便 Pandas DataFrame 與 Google Sheets 之間的轉換\n",
        "# google-auth, google-auth-oauthlib, google-auth-httplib2: Google 身份驗證相關\n",
        "# gradio: 建立一個互動式的網頁介面\n",
        "# pandas: 強大的資料處理和分析工具\n",
        "# beautifulsoup4: 用於解析 HTML 網頁內容，方便抓取資料\n",
        "# google-generativeai: 呼叫 Google 的生成式 AI 模型 (Gemini)\n",
        "# python-dateutil: 處理日期和時間，特別是時區問題\n",
        "!pip -q install gspread gspread_dataframe google-auth google-auth-oauthlib google-auth-httplib2 \\\n",
        "               gradio pandas beautifulsoup4 google-generativeai python-dateutil"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb8bf7bf"
      },
      "source": [
        "請保留下面這個儲存格 (設定您的 Google Sheet 連結、工作表名稱和時區)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae4f6ef3"
      },
      "source": [
        "# 設定您的 Google Sheet 連結、工作表名稱和時區\n",
        "# 請將 SHEET_URL 替換成您自己的 Google Sheet 連結\n",
        "SHEET_URL = \"https://docs.google.com/spreadsheets/d/163AOmd5HnH9sxzYJo4BwZeE87UFr3k5XxuggcRNsZCs/edit?usp=sharing\" # <-- 請確認這是您的 Google Sheet 網址\n",
        "INPUT_WORKSHEET_NAME = \"工作表1\" # <-- 開放式回答資料所在的工作表名稱\n",
        "OUTPUT_WORKSHEET_NAME = \"分析結果\" # <-- 文本分析結果將寫入的工作表名稱 (我會自動建立)\n",
        "TIMEZONE = \"Asia/Taipei\" # 設定時區"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3681a8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db66aca5-26bf-4513-d1a0-5c44fb4300f5"
      },
      "source": [
        "# 確保指定的工作表 (worksheet) 在試算表中存在，如果不存在則創建一個新的\n",
        "def ensure_worksheet(sh, title, header):\n",
        "    print(f\"嘗試確保工作表 '{title}' 存在...\")\n",
        "    try:\n",
        "        ws = sh.worksheet(title) # 嘗試開啟現有的工作表\n",
        "        print(f\"工作表 '{title}' 已存在。\")\n",
        "    except gspread.WorksheetNotFound:\n",
        "        print(f\"工作表 '{title}' 不存在，嘗試創建...\")\n",
        "        try:\n",
        "            # 如果找不到，則新增一個工作表，並設定初始的行列數\n",
        "            ws = sh.add_worksheet(title=title, rows=\"1000\", cols=str(len(header)+5))\n",
        "            print(f\"工作表 '{title}' 創建成功。\")\n",
        "            ws.update([header]) # 新增時寫入表頭\n",
        "            print(f\"已為工作表 '{title}' 寫入表頭。\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 創建工作表 '{title}' 失敗: {e}\")\n",
        "            raise # 創建失敗時重新拋出異常\n",
        "    # 再次檢查：若沒有表頭（工作表是空的或第一行不是預期的表頭），則清空並寫上表頭\n",
        "    try:\n",
        "        data = ws.get_all_values()\n",
        "        if not data or (data and data[0] != header):\n",
        "            print(f\"工作表 '{title}' 沒有表頭或表頭不符，清空並重新寫入表頭。\")\n",
        "            ws.clear() # 清空工作表內容\n",
        "            ws.update([header]) # 重新寫入表頭\n",
        "            print(f\"已為工作表 '{title}' 重新寫入表頭。\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 檢查或更新工作表 '{title}' 表頭失敗: {e}\")\n",
        "        # 這裡選擇不中斷程式，但記錄錯誤\n",
        "\n",
        "    print(f\"確保工作表 '{title}' 過程結束。\")\n",
        "    return ws\n",
        "\n",
        "# 讀取 DataFrame 的輔助函式\n",
        "def read_df(ws, header):\n",
        "    \"\"\"從 Google Sheet 工作表讀取資料到 DataFrame，並確保欄位和型態正確\"\"\"\n",
        "    df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "    if df is None or df.empty:\n",
        "        sheet_header = ws.get_all_values('A1:1')\n",
        "        cols = sheet_header[0] if sheet_header and sheet_header[0] else header\n",
        "        return pd.DataFrame(columns=cols)\n",
        "    df = df.fillna(\"\")\n",
        "    for c in header:\n",
        "        if c not in df.columns:\n",
        "            df[c] = \"\"\n",
        "    return df\n",
        "\n",
        "# 將 DataFrame 寫入 Google Sheet 的輔助函式\n",
        "def write_df(ws, df, header):\n",
        "    \"\"\"將 DataFrame 內容寫入 Google Sheet 工作表 (全量覆蓋)\"\"\"\n",
        "    if df.empty:\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "        return\n",
        "    df_out = df.copy()\n",
        "    for c in df_out.columns:\n",
        "        df_out[c] = df_out[c].astype(str)\n",
        "    ws.clear()\n",
        "    ws.update([header] + df_out[header].values.tolist())\n",
        "\n",
        "# 需要 tznow 函式來處理時間戳記\n",
        "def tznow():\n",
        "    from datetime import datetime as dt\n",
        "    from dateutil.tz import gettz\n",
        "    # 確保 TIMEZONE 變數已定義\n",
        "    try:\n",
        "        TIMEZONE\n",
        "    except NameError:\n",
        "        # 如果 TIMEZONE 未定義，給出警告並使用預設值\n",
        "        print(\"⚠️ 時區變數 TIMEZONE 未定義，請執行設定儲存格。這裡將使用預設值 Asia/Taipei。\")\n",
        "        TIMEZONE_DEFAULT = \"Asia/Taipei\"\n",
        "        return dt.now(gettz(TIMEZONE_DEFAULT))\n",
        "    # 如果 TIMEZONE 已定義，則使用它\n",
        "    return dt.now(gettz(TIMEZONE))\n",
        "\n",
        "# 確保 PTT 文章資料、輸入資料和分析結果的工作表存在並有正確的表頭\n",
        "# 使用前面定義的 ensure_worksheet 函式來處理\n",
        "print(\"確保 PTT 文章工作表...\")\n",
        "ws_ptt_posts = ensure_worksheet(sh, \"ptt_movie_posts\", PTT_HEADER) # PTT 文章工作表\n",
        "print(\"確保 輸入資料工作表...\")\n",
        "ws_input = ensure_worksheet(sh, INPUT_WORKSHEET_NAME, INPUT_HEADER) # 輸入資料工作表\n",
        "print(\"確保 分析結果工作表...\")\n",
        "ws_analysis = ensure_worksheet(sh, OUTPUT_WORKSHEET_NAME, ANALYSIS_HEADER) # 分析結果工作表\n",
        "\n",
        "print(\"所有必要工作表確保完成。\")"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "確保 PTT 文章工作表...\n",
            "嘗試確保工作表 'ptt_movie_posts' 存在...\n",
            "工作表 'ptt_movie_posts' 不存在，嘗試創建...\n",
            "工作表 'ptt_movie_posts' 創建成功。\n",
            "已為工作表 'ptt_movie_posts' 寫入表頭。\n",
            "確保工作表 'ptt_movie_posts' 過程結束。\n",
            "確保 輸入資料工作表...\n",
            "嘗試確保工作表 '工作表1' 存在...\n",
            "工作表 '工作表1' 已存在。\n",
            "工作表 '工作表1' 沒有表頭或表頭不符，清空並重新寫入表頭。\n",
            "已為工作表 '工作表1' 重新寫入表頭。\n",
            "確保工作表 '工作表1' 過程結束。\n",
            "確保 分析結果工作表...\n",
            "嘗試確保工作表 '分析結果' 存在...\n",
            "工作表 '分析結果' 不存在，嘗試創建...\n",
            "工作表 '分析結果' 創建成功。\n",
            "已為工作表 '分析結果' 寫入表頭。\n",
            "確保工作表 '分析結果' 過程結束。\n",
            "所有必要工作表確保完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a6a0ca1"
      },
      "source": [
        "請保留下面這個儲存格 (定義資料表的欄位名稱和初始化 DataFrame)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0835c55"
      },
      "source": [
        "# 定義不同資料表的欄位名稱 (Header)\n",
        "# PTT 文章資料的欄位\n",
        "PTT_HEADER = [\n",
        "    \"post_id\", \"title\", \"url\", \"date\", \"author\", \"nrec\", \"created_at\",\n",
        "    \"fetched_at\", \"content\"\n",
        "]\n",
        "# 輸入資料的欄位 (您需要根據您的 Sheet 調整)\n",
        "INPUT_HEADER = [\"Timestamp\", \"開放式回答\"] # <-- 請根據您的 Sheet 輸入工作表標頭調整這裡的欄位名稱\n",
        "# 文本分析結果的欄位\n",
        "ANALYSIS_HEADER = [\"term\", \"freq\", \"df_count\", \"tfidf_mean\", \"examples\"]\n",
        "\n",
        "# 初始化空的 DataFrame，後續由 Gradio 讀取或爬取後填充\n",
        "ptt_posts_df = pd.DataFrame(columns=PTT_HEADER)\n",
        "input_responses_df = pd.DataFrame(columns=INPUT_HEADER)\n",
        "terms_df = pd.DataFrame(columns=ANALYSIS_HEADER)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ddbef19"
      },
      "source": [
        "請保留下面這個儲存格 (進行 Google 身份驗證)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1de3818f"
      },
      "source": [
        "# 進行 Google 身份驗證\n",
        "# 這會在 Colab 環境中跳出一個視窗，引導您完成授權流程\n",
        "# 授權後，程式碼才能存取您的 Google Drive 和 Google Sheets\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# 使用您的 Google 憑證來授權 gspread\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "# 初始化 gspread 客戶端，之後就可以用 gc 來操作您的 Google Sheets\n",
        "gc = gspread.authorize(creds)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2eb938f"
      },
      "source": [
        "請保留下面這個儲存格 (確保 Google Sheet 試算表存在)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de441dc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "661a5f82-446c-4309-e798-bb6a5e78b943"
      },
      "source": [
        "# 確保指定的 Google Sheet 存在，如果不存在則創建一個新的\n",
        "def ensure_spreadsheet(url):\n",
        "    try:\n",
        "        # Try to open the spreadsheet using the URL\n",
        "        sh = gc.open_by_url(url)\n",
        "        print(f\"✅ Successfully opened spreadsheet from URL: {url}\")\n",
        "    except gspread.SpreadsheetNotFound:\n",
        "        print(f\"⚠️ Spreadsheet not found at URL: {url}. Attempting to create a new one (this might not be the intended behavior if you expected to use an existing sheet).\")\n",
        "        # If not found by URL, try creating one. Note: creating by URL is not standard gspread.\n",
        "        # A more typical approach is to create by name or rely on an existing sheet.\n",
        "        # For this scenario, let's assume the user wants to use the sheet at the URL.\n",
        "        # If it's not found, there might be an issue with the URL or permissions.\n",
        "        # We'll re-raise the error or return None to indicate failure.\n",
        "        raise # Re-raise the error to inform the user the sheet wasn't found\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Failed to open spreadsheet from URL {url}: {e}\")\n",
        "        raise # Re-raise any other exceptions\n",
        "\n",
        "    return sh\n",
        "\n",
        "# Use the provided SHEET_URL to ensure the spreadsheet exists and is opened\n",
        "try:\n",
        "    sh = ensure_spreadsheet(SHEET_URL)\n",
        "    print(f\"✅ Google Sheet '{SHEET_URL}' 確保完成，準備檢查工作表。\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ 無法開啟或建立 Google Sheet: {e}\")\n",
        "    # Depending on the severity, you might want to exit or disable parts of the app\n",
        "    sh = None # Set sh to None to prevent further errors if spreadsheet opening failed"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully opened spreadsheet from URL: https://docs.google.com/spreadsheets/d/163AOmd5HnH9sxzYJo4BwZeE87UFr3k5XxuggcRNsZCs/edit?usp=sharing\n",
            "✅ Google Sheet 'https://docs.google.com/spreadsheets/d/163AOmd5HnH9sxzYJo4BwZeE87UFr3k5XxuggcRNsZCs/edit?usp=sharing' 確保完成，準備檢查工作表。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7e3cc6d"
      },
      "source": [
        "請保留下面這個儲存格 (確保 Google Sheet 工作表存在並定義輔助函式 read_df, write_df, tznow)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "314be9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e9f54d4-fb81-4415-d63d-4fb237af605f"
      },
      "source": [
        "# 確保指定的工作表 (worksheet) 在試算表中存在，並檢查/補上表頭\n",
        "def ensure_worksheet(sh, title, header):\n",
        "    if sh is None:\n",
        "        print(f\"⚠️ 試算表物件為 None，無法確保工作表 '{title}'。請檢查試算表開啟步驟。\")\n",
        "        return None\n",
        "\n",
        "    print(f\"嘗試確保工作表 '{title}' 存在於試算表 '{sh.title}'...\")\n",
        "    try:\n",
        "        ws = sh.worksheet(title) # 嘗試開啟現有的工作表\n",
        "        print(f\"工作表 '{title}' 已存在。\")\n",
        "    except gspread.WorksheetNotFound:\n",
        "        print(f\"工作表 '{title}' 不存在於試算表 '{sh.title}'，嘗試創建...\")\n",
        "        try:\n",
        "            # 如果找不到，則新增一個工作表，並設定初始的行列數\n",
        "            ws = sh.add_worksheet(title=title, rows=\"1000\", cols=str(len(header)+5))\n",
        "            print(f\"工作表 '{title}' 創建成功。\")\n",
        "            # ws.update([header]) # 新增時寫入表頭 - Moved below to handle existing sheets without headers too\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 創建工作表 '{title}' 失敗: {e}\")\n",
        "            # Depending on the severity, you might want to exit or disable parts of the app\n",
        "            return None # Return None if worksheet creation fails\n",
        "\n",
        "    # 再次檢查：若沒有表頭（工作表是空的或第一行不是預期的表頭），則清空並寫上表頭\n",
        "    try:\n",
        "        data = ws.get_all_values('A1:1') # Only read the first row\n",
        "        if not data or data[0] != header:\n",
        "            print(f\"工作表 '{title}' 沒有表頭或表頭不符，清空並重新寫入表頭。\")\n",
        "            ws.clear() # 清空工作表內容\n",
        "            ws.update([header]) # 重新寫入表頭\n",
        "            print(f\"已為工作表 '{title}' 重新寫入表頭。\")\n",
        "        else:\n",
        "            print(f\"工作表 '{title}' 表頭檢查正常。\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 檢查或更新工作表 '{title}' 表頭失敗: {e}\")\n",
        "        # 這裡選擇不中斷程式，但記錄錯誤\n",
        "\n",
        "    print(f\"確保工作表 '{title}' 過程結束。\")\n",
        "    return ws\n",
        "\n",
        "# 讀取 DataFrame 的輔助函式\n",
        "def read_df(ws, header):\n",
        "    \"\"\"從 Google Sheet 工作表讀取資料到 DataFrame，並確保欄位和型態正確\"\"\"\n",
        "    if ws is None:\n",
        "        print(\"⚠️ 工作表物件為 None，無法讀取 DataFrame。\")\n",
        "        cols = header # Use provided header for empty DataFrame\n",
        "        return pd.DataFrame(columns=cols)\n",
        "\n",
        "    try:\n",
        "        df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "        if df is None or df.empty:\n",
        "            print(f\"ℹ️ 工作表 '{ws.title}' 為空或無法讀取 DataFrame。\")\n",
        "            sheet_header = ws.get_all_values('A1:1')\n",
        "            cols = sheet_header[0] if sheet_header and sheet_header[0] else header\n",
        "            return pd.DataFrame(columns=cols)\n",
        "\n",
        "        df = df.fillna(\"\")\n",
        "        # Ensure all header columns exist, add if missing\n",
        "        for c in header:\n",
        "            if c not in df.columns:\n",
        "                print(f\"⚠️ 工作表 '{ws.title}' 缺少欄位 '{c}'，已新增空欄位。\")\n",
        "                df[c] = \"\"\n",
        "        # Optional: Reorder columns to match header\n",
        "        df = df[header]\n",
        "\n",
        "        print(f\"✅ 從工作表 '{ws.title}' 讀取 {len(df)} 筆資料。\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 從工作表 '{ws.title}' 讀取 DataFrame 失敗: {e}\")\n",
        "        cols = ws.get_all_values('A1:1')[0] if ws.get_all_values('A1:1') else header\n",
        "        return pd.DataFrame(columns=cols)\n",
        "\n",
        "\n",
        "# 將 DataFrame 寫入 Google Sheet 的輔助函式\n",
        "def write_df(ws, df, header):\n",
        "    \"\"\"將 DataFrame 內容寫入 Google Sheet 工作表 (全量覆蓋)\"\"\"\n",
        "    if ws is None:\n",
        "        print(\"⚠️ 工作表物件為 None，無法寫入 DataFrame。\")\n",
        "        return\n",
        "\n",
        "    print(f\"嘗試將 {len(df)} 筆資料寫入工作表 '{ws.title}'...\")\n",
        "    try:\n",
        "        if df.empty:\n",
        "            ws.clear()\n",
        "            ws.update([header])\n",
        "            print(f\"✅ 工作表 '{ws.title}' 已清空並寫入表頭。\")\n",
        "            return\n",
        "\n",
        "        df_out = df.copy()\n",
        "        # Ensure only header columns are written and in the correct order\n",
        "        df_out = df_out.reindex(columns=header, fill_value=\"\")\n",
        "        for c in df_out.columns:\n",
        "            df_out[c] = df_out[c].astype(str)\n",
        "\n",
        "        ws.clear()\n",
        "        ws.update([header] + df_out[header].values.tolist())\n",
        "        print(f\"✅ 已將 {len(df)} 筆資料寫入工作表 '{ws.title}'。\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 將 DataFrame 寫入工作表 '{ws.title}' 失敗: {e}\")\n",
        "\n",
        "\n",
        "# 需要 tznow 函式來處理時間戳記\n",
        "def tznow():\n",
        "    from datetime import datetime as dt\n",
        "    from dateutil.tz import gettz\n",
        "    # 確保 TIMEZONE 變數已定義\n",
        "    try:\n",
        "        TIMEZONE\n",
        "    except NameError:\n",
        "        # 如果 TIMEZONE 未定義，給出警告並使用預設值\n",
        "        print(\"⚠️ 時區變數 TIMEZONE 未定義，請執行設定儲存格。這裡將使用預設值 Asia/Taipei。\")\n",
        "        TIMEZONE_DEFAULT = \"Asia/Taipei\"\n",
        "        return dt.now(gettz(TIMEZONE_DEFAULT))\n",
        "    # 如果 TIMEZONE 已定義，則使用它\n",
        "    return dt.now(gettz(TIMEZONE))\n",
        "\n",
        "# 確保 PTT 文章資料、輸入資料和分析結果的工作表存在並有正確的表頭\n",
        "# 使用前面定義的 ensure_worksheet 函式來處理\n",
        "# Ensure the spreadsheet object 'sh' is available before calling ensure_worksheet\n",
        "if 'sh' in globals() and sh is not None:\n",
        "    print(\"確保 PTT 文章工作表...\")\n",
        "    ws_ptt_posts = ensure_worksheet(sh, \"ptt_movie_posts\", PTT_HEADER) # PTT 文章工作表\n",
        "    print(\"確保 輸入資料工作表...\")\n",
        "    ws_input = ensure_worksheet(sh, INPUT_WORKSHEET_NAME, INPUT_HEADER) # 輸入資料工作表\n",
        "    print(\"確保 分析結果工作表...\")\n",
        "    ws_analysis = ensure_worksheet(sh, OUTPUT_WORKSHEET_NAME, ANALYSIS_HEADER) # 分析結果工作表\n",
        "\n",
        "    print(\"所有必要工作表確保完成。\")\n",
        "else:\n",
        "    print(\"⚠️ 試算表物件 'sh' 未成功初始化，跳過工作表確保步驟。\")"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "確保 PTT 文章工作表...\n",
            "嘗試確保工作表 'ptt_movie_posts' 存在於試算表 'hw4'...\n",
            "工作表 'ptt_movie_posts' 已存在。\n",
            "工作表 'ptt_movie_posts' 表頭檢查正常。\n",
            "確保工作表 'ptt_movie_posts' 過程結束。\n",
            "確保 輸入資料工作表...\n",
            "嘗試確保工作表 '工作表1' 存在於試算表 'hw4'...\n",
            "工作表 '工作表1' 已存在。\n",
            "工作表 '工作表1' 表頭檢查正常。\n",
            "確保工作表 '工作表1' 過程結束。\n",
            "確保 分析結果工作表...\n",
            "嘗試確保工作表 '分析結果' 存在於試算表 'hw4'...\n",
            "工作表 '分析結果' 已存在。\n",
            "工作表 '分析結果' 表頭檢查正常。\n",
            "確保工作表 '分析結果' 過程結束。\n",
            "所有必要工作表確保完成。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a74eddae"
      },
      "source": [
        "請保留下面這個儲存格 (安裝必要的 Python 函式庫)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef5eedee"
      },
      "source": [
        "# 安裝必要的 Python 套件\n",
        "# 這邊列出了我們這個專案會用到的所有套件\n",
        "# gspread: 用來操作 Google Sheets\n",
        "# gspread_dataframe: 方便 Pandas DataFrame 與 Google Sheets 之間的轉換\n",
        "# google-auth, google-auth-oauthlib, google-auth-httplib2: Google 身份驗證相關\n",
        "# gradio: 建立一個互動式的網頁介面\n",
        "# pandas: 強大的資料處理和分析工具\n",
        "# beautifulsoup4: 用於解析 HTML 網頁內容，方便抓取資料\n",
        "# google-generativeai: 呼叫 Google 的生成式 AI 模型 (Gemini)\n",
        "# python-dateutil: 處理日期和時間，特別是時區問題\n",
        "!pip -q install gspread gspread_dataframe google-auth google-auth-oauthlib google-auth-httplib2 \\\n",
        "               gradio pandas beautifulsoup4 google-generativeai python-dateutil"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6df4c328"
      },
      "source": [
        "請保留下面這個儲存格 (匯入專案所需的函式庫)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c91cca7"
      },
      "source": [
        "# 匯入專案所需的函式庫\n",
        "# 包含了處理時間、資料科學工具、網頁操作、文本分析以及 Google 服務的函式庫\n",
        "\n",
        "import os, time, uuid, re, json, datetime\n",
        "from datetime import datetime as dt, timedelta\n",
        "from dateutil.tz import gettz # 處理時區相關功能，確保時間正確\n",
        "\n",
        "import pandas as pd # Pandas DataFrame 是資料處理的核心\n",
        "import gradio as gr # Gradio 讓我們快速建立一個分享的介面\n",
        "import requests # 用於發送 HTTP 請求，例如取得網頁原始碼\n",
        "from bs4 import BeautifulSoup # BeautifulSoup 協助解析 HTML 結構\n",
        "\n",
        "# 文本分析常用的工具\n",
        "from collections import Counter, defaultdict # 計算詞頻、處理字典\n",
        "import numpy as np # 數值計算的好幫手\n",
        "from scipy.sparse import csr_matrix # 如果使用到 TF-IDF 或其他向量化方法時可能會需要\n",
        "\n",
        "# 呼叫 Google 的生成式 AI 模型，例如 Gemini\n",
        "import google.generativeai as genai\n",
        "\n",
        "# 與 Google 服務 (特別是 Google Sheets) 互動的函式庫\n",
        "from google.colab import auth # 在 Colab 環境中進行 Google 身份驗證\n",
        "import gspread # 讀取和寫入 Google Sheets\n",
        "from gspread_dataframe import set_with_dataframe, get_as_dataframe # 更方便地處理 DataFrame 與 Sheet 之間的資料傳輸\n",
        "from google.auth.transport.requests import Request # 處理驗證過程中的 HTTP 請求\n",
        "from google.oauth2 import service_account # 服務帳戶驗證 (如果您使用服務帳戶金鑰的話)\n",
        "from google.auth import default # 使用預設的身份驗證憑證"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35381d80"
      },
      "source": [
        "請保留下面這個儲存格 (設定 Gemini API 金鑰並初始化模型)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d0e158b"
      },
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# 從 Colab Secrets 中獲取 API 金鑰\n",
        "# 請將您的 Gemini API 金鑰儲存在 Colab 的 Secrets 中，名稱設定為 'GOOGLE_API_KEY'\n",
        "# 如何設定 Secrets: 在 Colab 左側面板點擊「🔑」，新增一個 Secret，名稱為 GOOGLE_API_KEY，值貼上您的 API 金鑰\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# 使用獲取的金鑰配置 genai\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# 初始化 Gemini 模型，這裡使用 'gemini-2.5-pro'\n",
        "# 您可以根據需求更換模型名稱\n",
        "model = genai.GenerativeModel('gemini-2.5-pro')"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "415e277f"
      },
      "source": [
        "請保留下面這個儲存格 (定義核心功能函式：PTT 爬蟲、Sheet 讀取、文本分析、AI 生成)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cc5bdc3"
      },
      "source": [
        "# ==============\n",
        "# PTT 電影版爬蟲函式\n",
        "# ==============\n",
        "\n",
        "# (保留原有的 PTT 爬蟲輔助函式 _get_soup, _get_prev_index_url, _parse_nrec, _extract_post_list, _clean_ptt_content)\n",
        "PTT_MOVIE_INDEX = \"https://www.ptt.cc/bbs/movie/index.html\" # PTT 電影版首頁 URL\n",
        "PTT_COOKIES = {\"over18\": \"1\"} # 用於繞過 PTT 的滿 18 歲驗證 (會話狀態維持)\n",
        "\n",
        "def _get_soup(url):\n",
        "    headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
        "    r = requests.get(url, timeout=15, headers=headers, cookies=PTT_COOKIES)\n",
        "    r.raise_for_status()\n",
        "    return BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "def _get_prev_index_url(soup):\n",
        "    btns = soup.select(\"div.btn-group-paging a.btn.wide\")\n",
        "    for a in btns:\n",
        "        if \"上頁\" in a.get_text(strip=True):\n",
        "            href = a.get(\"href\")\n",
        "            if href:\n",
        "                from urllib.parse import urljoin\n",
        "                return urljoin(PTT_MOVIE_INDEX, href)\n",
        "    return None\n",
        "\n",
        "def _parse_nrec(nrec_span):\n",
        "    if not nrec_span: return 0\n",
        "    txt = nrec_span.get_text(strip=True)\n",
        "    if txt == \"爆\": return 100\n",
        "    if txt.startswith(\"X\"):\n",
        "        try: return -int(txt[1:])\n",
        "        except: return -10\n",
        "    try: return int(txt)\n",
        "    except: return 0\n",
        "\n",
        "def _extract_post_list(soup):\n",
        "    posts = []\n",
        "    for r in soup.select(\"div.r-ent\"):\n",
        "        a = r.select_one(\"div.title a\")\n",
        "        if not a: continue\n",
        "        title = a.get_text(strip=True)\n",
        "        url = \"https://www.ptt.cc\" + a.get(\"href\")\n",
        "        author = r.select_one(\"div.author\").get_text(strip=True)\n",
        "        date = r.select_one(\"div.date\").get_text(strip=True)\n",
        "        nrec = _parse_nrec(r.select_one(\"div.nrec span\"))\n",
        "        posts.append({\"title\": title, \"url\": url, \"author\": author, \"date\": date, \"nrec\": nrec})\n",
        "    return posts\n",
        "\n",
        "def _clean_ptt_content(soup):\n",
        "    for p in soup.select(\"div.push\"): p.decompose()\n",
        "    main = soup.select_one(\"#main-content\")\n",
        "    if not main: return \"\", \"\"\n",
        "    metas = main.select(\"div.article-metaline, div.article-metaline-right\")\n",
        "    for m in metas: m.decompose()\n",
        "    text = main.get_text(\"\\n\", strip=True)\n",
        "    if \"--\" in text: text = text.split(\"--\")[0].strip()\n",
        "    title_tag = soup.select_one(\"span.article-meta-value\")\n",
        "    meta_title = title_tag.get_text(strip=True) if title_tag else \"\"\n",
        "    return text, meta_title\n",
        "\n",
        "\n",
        "# 主要爬蟲函式：從 PTT 電影版抓取文章\n",
        "# 抓取結果會寫入 ws_ptt_posts 工作表\n",
        "def crawl_ptt_movie(index_pages=3, min_push=0, keyword=\"\"):\n",
        "    \"\"\"從最新 index.html 往前翻 index_pages 頁，抓滿足條件的文章並寫入 Sheet\"\"\"\n",
        "    global ptt_posts_df, ws_ptt_posts # 宣告使用全域變數\n",
        "    url = PTT_MOVIE_INDEX\n",
        "    all_rows = []\n",
        "    # 先從 Sheet 讀取現有的 PTT 文章，用於去重\n",
        "    ptt_posts_df = read_df(ws_ptt_posts, PTT_HEADER) # 從 PTT 工作表讀取\n",
        "    seen_urls = set(ptt_posts_df[\"url\"].tolist()) if not ptt_posts_df.empty else set()\n",
        "\n",
        "    for _ in range(int(index_pages)):\n",
        "        try:\n",
        "            soup = _get_soup(url)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 抓取頁面失敗 {url}: {e}\")\n",
        "            break\n",
        "        posts = _extract_post_list(soup)\n",
        "        for p in posts:\n",
        "            if p[\"nrec\"] < int(min_push): continue\n",
        "            if keyword and (keyword not in p[\"title\"]): continue\n",
        "            if p[\"url\"] in seen_urls: continue\n",
        "\n",
        "            try:\n",
        "                art_soup = _get_soup(p[\"url\"])\n",
        "                content, meta_title = _clean_ptt_content(art_soup)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 抓取文章內文失敗 {p['url']}: {e}\")\n",
        "                content, meta_title = \"\", \"\"\n",
        "\n",
        "            final_title = p[\"title\"] if p[\"title\"] else (meta_title or \"（無標題）\")\n",
        "\n",
        "            all_rows.append({\n",
        "                \"post_id\": str(uuid.uuid4())[:8],\n",
        "                \"title\": final_title[:200],\n",
        "                \"url\": p[\"url\"],\n",
        "                \"date\": p[\"date\"],\n",
        "                \"author\": p[\"author\"],\n",
        "                \"nrec\": str(p[\"nrec\"]),\n",
        "                \"created_at\": tznow().isoformat(), # 需要 tznow 函式\n",
        "                \"fetched_at\": tznow().isoformat(), # 需要 tznow 函式\n",
        "                \"content\": content\n",
        "            })\n",
        "            seen_urls.add(p[\"url\"])\n",
        "\n",
        "        prev = _get_prev_index_url(soup)\n",
        "        if not prev: break\n",
        "        url = prev\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    if all_rows:\n",
        "        new_df = pd.DataFrame(all_rows, columns=PTT_HEADER)\n",
        "        # 合併新抓取的資料到現有 DataFrame\n",
        "        ptt_posts_df = pd.concat([ptt_posts_df, new_df], ignore_index=True)\n",
        "        # 將更新後的 DataFrame 寫回 PTT 工作表\n",
        "        write_df(ws_ptt_posts, ptt_posts_df, PTT_HEADER)\n",
        "        return f\"✅ 取得 {len(all_rows)} 篇文章（已寫入 Sheet 的 ptt_movie_posts 工作表）\", ptt_posts_df\n",
        "    else:\n",
        "        return \"ℹ️ 沒有新文章符合條件（或內容已在 Sheet 的 ptt_movie_posts 工作表）\", ptt_posts_df\n",
        "\n",
        "\n",
        "# ==============\n",
        "# 文本分析（jieba + TF/IDF + bigram）函式\n",
        "# ==============\n",
        "import re\n",
        "try:\n",
        "    import jieba\n",
        "except ImportError:\n",
        "    jieba = None\n",
        "    print(\"⚠️ 未安裝 jieba，中文斷詞將使用較簡單的空白字元分割。請考慮安裝 jieba 以獲得更好的斷詞效果。\")\n",
        "\n",
        "def _tokenize_zh(text):\n",
        "    text = re.sub(r\"[^\\u4e00-\\u9fffA-Za-z0-9,.!?:;\\'\\\"()]+\", \" \", text)\n",
        "    if not jieba:\n",
        "        return [t.strip() for t in text.split() if len(t.strip()) > 1]\n",
        "    tokens = [w.strip() for w in jieba.lcut(text) if len(w.strip()) > 1]\n",
        "    return tokens\n",
        "\n",
        "# 從 Google Sheet 讀取開放式回答資料的函式 (保留)\n",
        "def read_open_ended_responses(worksheet_name=INPUT_WORKSHEET_NAME, column_name=\"開放式回答\"):\n",
        "    \"\"\"從指定的 Google Sheet 工作表和欄位讀取文字資料\"\"\"\n",
        "    global sh, ws_input # 使用前面已經授權並開啟的試算表物件和輸入工作表物件\n",
        "    try:\n",
        "        # 嘗試開啟指定的工作表，如果指定的是 INPUT_WORKSHEET_NAME，則直接使用 ws_input\n",
        "        ws = sh.worksheet(worksheet_name) if worksheet_name != INPUT_WORKSHEET_NAME else ws_input\n",
        "        df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "        if df is None or df.empty:\n",
        "            return pd.DataFrame(columns=[column_name]), f\"ℹ️ 工作表 '{worksheet_name}' 沒有資料。\"\n",
        "\n",
        "        if column_name not in df.columns:\n",
        "             return pd.DataFrame(columns=[column_name]), f\"⚠️ 工作表 '{worksheet_name}' 中找不到 '{column_name}' 欄位。\"\n",
        "        df = df.fillna(\"\")\n",
        "        return df[[column_name]], f\"✅ 從工作表 '{worksheet_name}' 讀取 {len(df)} 筆資料。\"\n",
        "\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return pd.DataFrame(columns=[column_name]), f\"⚠️ 找不到工作表 '{worksheet_name}'。\"\n",
        "    except Exception as e:\n",
        "        return pd.DataFrame(columns=[column_name]), f\"⚠️ 讀取工作表失敗: {e}\"\n",
        "\n",
        "\n",
        "# 主要文本分析函式 - 修改為接受 DataFrame 作為輸入\n",
        "def analyze_texts(df, text_column_name, topk=50, min_df=2):\n",
        "    \"\"\"從 DataFrame 中的指定文字欄位進行文本分析，結果寫入分析工作表\"\"\"\n",
        "    global ws_analysis # 使用前面確保存在的分析結果工作表\n",
        "    if df is None or df.empty or text_column_name not in df.columns:\n",
        "        return \"📭 沒有有效的文字資料進行分析。\", pd.DataFrame(columns=ANALYSIS_HEADER), \"\"\n",
        "\n",
        "    docs = df[text_column_name].tolist()\n",
        "    docs = [d for d in docs if d and isinstance(d, str)]\n",
        "\n",
        "    if not docs:\n",
        "         return \"📭 沒有有效的文字資料進行分析。\", pd.DataFrame(columns=ANALYSIS_HEADER), \"\"\n",
        "\n",
        "    # (保留原有的詞頻、文件頻率、TF-IDF、Bigram 計算邏輯)\n",
        "    freq = Counter()\n",
        "    df_cnt = defaultdict(int)\n",
        "    token_docs = []\n",
        "    for doc in docs:\n",
        "        toks = _tokenize_zh(doc)\n",
        "        token_docs.append(toks)\n",
        "        freq.update(toks)\n",
        "        for t in set(toks):\n",
        "            df_cnt[t] += 1\n",
        "\n",
        "    filtered_terms = [t for t in freq.keys() if df_cnt[t] >= int(min_df)]\n",
        "    freq = Counter({t: freq[t] for t in filtered_terms})\n",
        "    df_cnt = {t: df_cnt[t] for t in filtered_terms}\n",
        "\n",
        "    tfidf_map = {}\n",
        "    try:\n",
        "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "        vec = TfidfVectorizer(tokenizer=_tokenize_zh, lowercase=False)\n",
        "        X = vec.fit_transform(docs)\n",
        "        terms = vec.get_feature_names_out()\n",
        "        term_indices = [i for i, t in enumerate(terms) if t in filtered_terms]\n",
        "        X = X[:, term_indices]\n",
        "        terms = [terms[i] for i in term_indices]\n",
        "        tfidf_mean = X.mean(axis=0).A1 if X.shape[0] > 0 and X.shape[1] > 0 else np.array([])\n",
        "        tfidf_map = dict(zip(terms, tfidf_mean))\n",
        "    except ImportError:\n",
        "         print(\"⚠️ 未安裝 scikit-learn，無法計算 TF-IDF。\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ TF-IDF 計算失敗: {e}\")\n",
        "\n",
        "    from itertools import tee\n",
        "    def pairwise(iterable):\n",
        "        \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
        "        a, b = tee(iterable)\n",
        "        next(b, None)\n",
        "        return zip(a, b)\n",
        "    bigram_freq = Counter()\n",
        "    for toks in token_docs:\n",
        "        bigram_freq.update([\" \".join(bg) for bg in pairwise(toks)])\n",
        "\n",
        "    candidates = list(freq.keys())\n",
        "    candidates.sort(key=lambda t: (round(tfidf_map.get(t,0.0) if tfidf_map else 0.0, 6), freq.get(t,0)), reverse=True)\n",
        "    top_terms = candidates[:int(topk)]\n",
        "\n",
        "    examples = {}\n",
        "    for term in top_terms:\n",
        "        ex = \"\"\n",
        "        for doc in docs:\n",
        "            if term in doc:\n",
        "                i = doc.find(term)\n",
        "                s = max(0, i-15)\n",
        "                e = min(len(doc), i+len(term)+15)\n",
        "                ex = doc[s:e].replace(\"\\n\",\" \")\n",
        "                break\n",
        "        examples[term] = ex\n",
        "\n",
        "    rows = []\n",
        "    for t in top_terms:\n",
        "        rows.append({\n",
        "            \"term\": t,\n",
        "            \"freq\": str(freq.get(t,0)),\n",
        "            \"df_count\": str(df_cnt.get(t,0)),\n",
        "            \"tfidf_mean\": f\"{tfidf_map.get(t,0.0) if tfidf_map else 0.0:.6f}\",\n",
        "            \"examples\": examples.get(t, \"\")\n",
        "        })\n",
        "    terms_df = pd.DataFrame(rows, columns=ANALYSIS_HEADER)\n",
        "\n",
        "    # 將結果寫回 Google Sheet 的分析結果工作表\n",
        "    write_df(ws_analysis, terms_df, ANALYSIS_HEADER)\n",
        "\n",
        "    # 產生 Markdown 格式的摘要報告\n",
        "    md_lines = []\n",
        "    md_lines.append(f\"### 關鍵詞 Top {len(top_terms)}（依 TF-IDF 平均值優先，次序再以詞頻）\")\n",
        "    for i, t in enumerate(top_terms, 1):\n",
        "        tfidf_val = float(tfidf_map.get(t,0.0) if tfidf_map else 0.0)\n",
        "        md_lines.append(f\"{i}. **{t}** — tfidf≈{tfidf_val:.4f}；freq={freq.get(t,0)}；df={df_cnt.get(t,0)}\")\n",
        "    md_lines.append(\"\\n### 常見雙詞搭配（前 20）\")\n",
        "    for i, (bg, c) in enumerate(bigram_freq.most_common(20), 1):\n",
        "        md_lines.append(f\"{i}. {bg} — {c}\")\n",
        "\n",
        "    return f\"✅ 已完成文本分析，共處理 {len(docs)} 篇文檔；分析結果已寫入 Sheet 的 '{OUTPUT_WORKSHEET_NAME}' 工作表。\", terms_df, \"\\n\".join(md_lines)\n",
        "\n",
        "# 讀取 DataFrame 的輔助函式 (從之前的 PTT 爬蟲程式碼搬移過來並修改)\n",
        "def read_df(ws, header):\n",
        "    \"\"\"從 Google Sheet 工作表讀取資料到 DataFrame，並確保欄位和型態正確\"\"\"\n",
        "    df = get_as_dataframe(ws, evaluate_formulas=True, header=0)\n",
        "    if df is None or df.empty:\n",
        "        sheet_header = ws.get_all_values('A1:1')\n",
        "        cols = sheet_header[0] if sheet_header and sheet_header[0] else header\n",
        "        return pd.DataFrame(columns=cols)\n",
        "    df = df.fillna(\"\")\n",
        "    for c in header:\n",
        "        if c not in df.columns:\n",
        "            df[c] = \"\"\n",
        "    return df\n",
        "\n",
        "# 將 DataFrame 寫入 Google Sheet 的輔助函式 (從之前的 PTT 爬蟲程式碼搬移過來)\n",
        "def write_df(ws, df, header):\n",
        "    \"\"\"將 DataFrame 內容寫入 Google Sheet 工作表 (全量覆蓋)\"\"\"\n",
        "    if df.empty:\n",
        "        ws.clear()\n",
        "        ws.update([header])\n",
        "        return\n",
        "    df_out = df.copy()\n",
        "    for c in df_out.columns:\n",
        "        df_out[c] = df_out[c].astype(str)\n",
        "    ws.clear()\n",
        "    ws.update([header] + df_out[header].values.tolist())\n",
        "\n",
        "# AI 生成洞察和結論的函式 (保留)\n",
        "def generate_ai_output(terms_df):\n",
        "    \"\"\"使用 Gemini 模型生成洞察摘要和結論\"\"\"\n",
        "    # global model # 模型已在前面儲存格初始化\n",
        "    if terms_df is None or terms_df.empty:\n",
        "        return \"📭 沒有分析結果，無法生成 AI 摘要和結論。\", \"\", \"\"\n",
        "\n",
        "    input_text = \"請根據以下文本分析結果，生成 5 句洞察摘要和一段約 120 字的結論：\\n\\n\"\n",
        "    input_text += \"關鍵詞列表 (依重要性排序)：\\n\"\n",
        "    for _, r in terms_df.head(20).iterrows():\n",
        "        input_text += f\"- 詞彙: {r['term']}, 頻率: {r['freq']}, 文件數: {r['df_count']}, TF-IDF: {float(r['tfidf_mean']):.4f}, 範例: {r['examples']}\\n\"\n",
        "\n",
        "    input_text += \"\\n請注意：\\n1. 洞察摘要請使用條列式。\\n2. 結論請連貫成一段文字，約 120 字。\\n3. 請用繁體中文。\\n\\n範例輸出格式：\\n### 洞察摘要\\n- 洞察 1\\n- 洞察 2\\n...\\n### 結論\\n這裡是一段約 120 字的結論。\"\n",
        "\n",
        "    try:\n",
        "        # model = genai.GenerativeModel('gemini-2.5-pro') # 模型已在前面儲存格初始化\n",
        "        resp = model.generate_content(input_text)\n",
        "        ai_output = resp.text\n",
        "\n",
        "        insights = []\n",
        "        conclusion = \"\"\n",
        "        if \"### 洞察摘要\" in ai_output and \"### 結論\" in ai_output:\n",
        "            parts = ai_output.split(\"### 洞察摘要\")\n",
        "            if len(parts) > 1:\n",
        "                insights_part_conc_part = parts[1].split(\"### 結論\")\n",
        "                if len(insights_part_conc_part) > 1:\n",
        "                    insights_text = insights_part_conc_part[0].strip()\n",
        "                    insights = [line.strip(\"- \").strip() for line in insights_text.split(\"\\n\") if line.strip().startswith(\"-\")]\n",
        "                    conclusion = insights_part_conc_part[1].strip()\n",
        "                else:\n",
        "                    insights_text = insights_part_conc_part[0].strip()\n",
        "                    insights = [line.strip(\"- \").strip() for line in insights_text.split(\"\\n\") if line.strip().startswith(\"-\")]\n",
        "            elif \"### 結論\" in ai_output:\n",
        "                 parts = ai_output.split(\"### 結論\")\n",
        "                 if len(parts) > 1:\n",
        "                     conclusion = parts[1].strip()\n",
        "        else:\n",
        "             insights = [ai_output]\n",
        "             conclusion = \"（無法自動解析結論）\"\n",
        "\n",
        "        insights_md = \"### 洞察摘要\\n\" + (\"\\n\".join([f\"- {i}\" for i in insights]) if insights else \"（無）\")\n",
        "        conclusion_md = \"### 結論\\n\" + (conclusion if conclusion else \"（無）\")\n",
        "\n",
        "        return \"✅ 已成功生成 AI 摘要和結論。\", insights_md, conclusion_md\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ 生成 AI 摘要和結論失敗: {e}\", \"### 洞察摘要\\n（生成失敗）\", \"### 結論\\n（生成失敗）\"\n",
        "\n",
        "# 確保 TIMEZONE 變數已定義，如果沒有則使用預設值 Asia/Taipei\n",
        "try:\n",
        "    TIMEZONE\n",
        "except NameError:\n",
        "    print(\"⚠️ 時區變數 TIMEZONE 未定義，這裡將使用預設值 Asia/Taipei。\")\n",
        "    TIMEZONE = \"Asia/Taipei\"\n",
        "\n",
        "# 需要 tznow 函式才能讓 crawl_ptt_movie 和其他需要時間戳的函式運作\n",
        "def tznow():\n",
        "    from datetime import datetime as dt\n",
        "    from dateutil.tz import gettz\n",
        "    # 確保 TIMEZONE 變數已定義 (在此儲存格開頭已處理)\n",
        "    return dt.now(gettz(TIMEZONE))\n",
        "\n",
        "# 初始化空的 DataFrame，後續由 Gradio 讀取或爬取後填充\n",
        "ptt_posts_df = pd.DataFrame(columns=PTT_HEADER)\n",
        "input_responses_df = pd.DataFrame(columns=INPUT_HEADER)\n",
        "terms_df = pd.DataFrame(columns=ANALYSIS_HEADER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31ed3329"
      },
      "source": [
        "請保留下面這個儲存格 (定義 Gradio 介面需要呼叫的輔助函式)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ac9d8f2"
      },
      "source": [
        "# ==============\n",
        "# 輔助函式：資料處理與分析流程\n",
        "# 將部分需要在 Gradio 介面中呼叫的函式移到 Gradio 設定之前定義\n",
        "# ==============\n",
        "\n",
        "# 輔助函式：重新整理 PTT 文章資料 (從 Sheet 讀取)\n",
        "def refresh_ptt_posts():\n",
        "    global ptt_posts_df, ws_ptt_posts, PTT_HEADER # 確保使用全域變數和工作表物件\n",
        "    try:\n",
        "        # 確保 ws_ptt_posts 已被初始化 (如果前面的儲存格執行了)\n",
        "        if 'ws_ptt_posts' not in globals():\n",
        "             return pd.DataFrame(columns=PTT_HEADER), \"⚠️ PTT 文章工作表物件未初始化，請執行前面相關儲存格。\"\n",
        "\n",
        "        ptt_posts_df = read_df(ws_ptt_posts, PTT_HEADER).copy()\n",
        "        return ptt_posts_df, f\"✅ 已從 Sheet 載入 {len(ptt_posts_df)} 篇 PTT 文章。\"\n",
        "    except NameError:\n",
        "         return pd.DataFrame(columns=PTT_HEADER), \"⚠️ PTT_HEADER 或相關物件未定義，請執行前面相關儲存格。\"\n",
        "\n",
        "\n",
        "# 輔助函式：重新整理開放式回答資料 (從 Sheet 讀取)\n",
        "def refresh_input_responses(worksheet_name, column_name):\n",
        "    global input_responses_df, sh, ws_input, INPUT_HEADER # 確保使用全域變數和工作表物件\n",
        "    try:\n",
        "        # 確保 sh 和 ws_input 已被初始化 (如果前面的儲存格執行了)\n",
        "        if 'sh' not in globals() or 'ws_input' not in globals():\n",
        "            return pd.DataFrame(columns=INPUT_HEADER), \"⚠️ Google Sheet 物件或輸入資料工作表物件未初始化，請執行前面相關儲存格。\"\n",
        "\n",
        "        # 呼叫 oxbeeai_ni9s 中定義的 read_open_ended_responses 函式\n",
        "        input_responses_df, msg = read_open_ended_responses(worksheet_name, column_name)\n",
        "        return input_responses_df, msg\n",
        "    except NameError:\n",
        "        return pd.DataFrame(columns=INPUT_HEADER), \"⚠️ read_open_ended_responses 或相關物件未定義，請執行前面相關儲存格。\"\n",
        "\n",
        "\n",
        "# 輔助函式：執行 PTT 爬蟲並更新 DataFrame\n",
        "def run_ptt_crawl(index_pages, min_push, keyword):\n",
        "    global ptt_posts_df, ws_ptt_posts # 確保使用全域變數和工作表物件\n",
        "    try:\n",
        "        # 確保 ws_ptt_posts 已被初始化\n",
        "        if 'ws_ptt_posts' not in globals():\n",
        "            return pd.DataFrame(columns=PTT_HEADER), \"⚠️ PTT 文章工作表物件未初始化，請執行前面相關儲存格。\"\n",
        "\n",
        "        # 呼叫 oxbeeai_ni9s 中定義的 crawl_ptt_movie 函式\n",
        "        msg, ptt_posts_df = crawl_ptt_movie(index_pages, min_push, keyword)\n",
        "        # crawl_ptt_movie 內部已經將資料寫回 Sheet 了\n",
        "        return msg, ptt_posts_df\n",
        "    except NameError:\n",
        "        return pd.DataFrame(columns=PTT_HEADER), \"⚠️ crawl_ptt_movie 或相關物件未定義，請執行前面相關儲存格。\"\n",
        "\n",
        "\n",
        "# 輔助函式：執行文本分析和 AI 生成\n",
        "def perform_analysis_and_ai(data_source, input_col, topk, min_df):\n",
        "    global ptt_posts_df, input_responses_df, terms_df # 確保使用全域變數\n",
        "    df_to_analyze = pd.DataFrame()\n",
        "    text_column = \"\"\n",
        "\n",
        "    if data_source == \"PTT 文章 (已爬取)\":\n",
        "        df_to_analyze = ptt_posts_df\n",
        "        # 分析 PTT 文章時，合併 title 和 content 作為分析文本\n",
        "        df_to_analyze[\"combined_text\"] = df_to_analyze[\"title\"].fillna(\"\") + \"\\n\" + df_to_analyze[\"content\"].fillna(\"\")\n",
        "        text_column = \"combined_text\"\n",
        "    elif data_source == \"開放式回答 (從 Sheet 讀取)\":\n",
        "        df_to_analyze = input_responses_df\n",
        "        text_column = input_col # 使用使用者指定的欄位名稱\n",
        "        if text_column not in df_to_analyze.columns:\n",
        "             return \"⚠️ 選擇的資料來源或欄位名稱有誤。\", pd.DataFrame(columns=ANALYSIS_HEADER), \"\", \"\", \"\" # 額外返回空字串給 AI 輸出區域\n",
        "\n",
        "    if df_to_analyze.empty:\n",
        "        return \"📭 沒有資料可以分析。\", pd.DataFrame(columns=ANALYSIS_HEADER), \"\", \"\", \"\"\n",
        "\n",
        "    # 呼叫 oxbeeai_ni9s 中定義的 analyze_texts 函式進行分析\n",
        "    msg, terms_df, md_report = analyze_texts(df_to_analyze, text_column, topk, min_df)\n",
        "\n",
        "    # 呼叫 oxbeeai_ni9s 中定義的 generate_ai_output 函式生成 AI 洞察和結論\n",
        "    ai_msg, insights_md, conclusion_md = generate_ai_output(terms_df)\n",
        "\n",
        "    # 返回分析結果訊息、分析結果 DataFrame、Markdown 報告、AI 洞察和結論\n",
        "    return msg, terms_df, md_report, insights_md, conclusion_md"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caba7a29"
      },
      "source": [
        "請保留下面這個儲存格 (設定並啟動 Gradio 互動式介面)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "bcca8037",
        "outputId": "d0946c06-5e26-498f-8f3c-1674b89cce37"
      },
      "source": [
        "# ==============\n",
        "# Gradio 介面\n",
        "# 這是整個應用程式的網頁介面部分，使用 Gradio 函式庫建立。\n",
        "# 它包含了不同的分頁，用於執行爬蟲、讀取 Sheet 資料、文本分析和 AI 生成摘要。\n",
        "# ==============\n",
        "\n",
        "# 使用 gr.Blocks 建立介面\n",
        "with gr.Blocks(title=\"文本分析與 AI 摘要工具\") as demo:\n",
        "    gr.Markdown(\"# 📝 文字資料分析與 AI 摘要工具\") # 主標題\n",
        "\n",
        "    # --- 資料獲取分頁 ---\n",
        "    with gr.Tab(\"資料獲取 (PTT & Sheet)\"):\n",
        "        gr.Markdown(\"### 從 PTT 電影版爬取文章\")\n",
        "        with gr.Row():\n",
        "            ptt_pages = gr.Number(value=3, label=\"往前爬取頁數\", precision=0)\n",
        "            ptt_min_push = gr.Number(value=0, label=\"最低推文數\", precision=0)\n",
        "            ptt_keyword = gr.Textbox(label=\"標題關鍵字（可空白）\")\n",
        "        btn_crawl_ptt = gr.Button(\"🕷️ 開始爬取 PTT\")\n",
        "        msg_crawl_ptt = gr.Markdown() # 顯示爬蟲結果訊息\n",
        "        btn_refresh_ptt = gr.Button(\"🔄 從 Sheet 載入已爬取文章\")\n",
        "        msg_refresh_ptt = gr.Markdown()\n",
        "        grid_ptt_posts = gr.Dataframe(value=ptt_posts_df, label=\"已爬取的 PTT 文章 (來自 Sheet)\", interactive=False)\n",
        "\n",
        "        gr.Markdown(\"### 從 Google Sheet 讀取開放式回答\")\n",
        "        # 這裡使用 Textbox 讓使用者輸入工作表名稱和欄位名稱，而不是寫死變數\n",
        "        input_sheet_name = gr.Textbox(label=\"輸入資料所在工作表名稱\", value=INPUT_WORKSHEET_NAME) # 使用預設值\n",
        "        input_col_name = gr.Textbox(label=\"開放式回答欄位名稱\", value=INPUT_HEADER[1]) # 使用預設值\n",
        "        btn_read_sheet = gr.Button(\"📥 從 Sheet 讀取開放式回答\")\n",
        "        msg_read_sheet = gr.Markdown() # 顯示讀取結果訊息\n",
        "        grid_input_responses = gr.Dataframe(value=input_responses_df, label=\"從 Sheet 讀取的開放式回答\", interactive=False)\n",
        "\n",
        "\n",
        "    # --- 文本分析與 AI 分頁 ---\n",
        "    with gr.Tab(\"文本分析與 AI 摘要\"):\n",
        "        gr.Markdown(\"### 文本分析設定\")\n",
        "        data_source_radio = gr.Radio([\"PTT 文章 (已爬取)\", \"開放式回答 (從 Sheet 讀取)\"], label=\"選擇分析資料來源\", value=\"開放式回答 (從 Sheet 讀取)\")\n",
        "        analysis_topk = gr.Number(value=50, label=\"輸出 Top K 關鍵詞\", precision=0)\n",
        "        analysis_min_df = gr.Number(value=2, label=\"最低文件頻率 (Min DF)\", precision=0)\n",
        "        btn_analyze = gr.Button(\"🔬 執行文本分析與 AI 生成\") # 將分析和 AI 生成合併到一個按鈕\n",
        "        msg_analyze = gr.Markdown() # 顯示分析結果訊息\n",
        "\n",
        "        gr.Markdown(\"### 文本分析報告（關鍵詞與雙詞搭配）\")\n",
        "        out_analysis_report = gr.Markdown() # 顯示 Markdown 格式的分析報告\n",
        "        grid_terms = gr.Dataframe(value=terms_df, label=\"關鍵詞分析結果 (已寫入 Sheet)\", interactive=False)\n",
        "\n",
        "        gr.Markdown(\"### AI 生成洞察與結論\")\n",
        "        out_ai_insights = gr.Markdown(\"### 洞察摘要\\n（待生成）\") # 顯示 AI 洞察\n",
        "        out_ai_conclusion = gr.Markdown(\"### 結論\\n（待生成）\") # 顯示 AI 結論\n",
        "\n",
        "\n",
        "    # === 綁定介面元件與後端函式 ===\n",
        "\n",
        "    # 資料獲取分頁的按鈕綁定\n",
        "    btn_crawl_ptt.click(run_ptt_crawl, inputs=[ptt_pages, ptt_min_push, ptt_keyword], outputs=[msg_crawl_ptt, grid_ptt_posts])\n",
        "    btn_refresh_ptt.click(refresh_ptt_posts, outputs=[grid_ptt_posts, msg_refresh_ptt])\n",
        "    # 呼叫 refresh_input_responses，傳入使用者在介面輸入的工作表名稱和欄位名稱\n",
        "    btn_read_sheet.click(refresh_input_responses, inputs=[input_sheet_name, input_col_name], outputs=[grid_input_responses, msg_read_sheet])\n",
        "\n",
        "    # 文本分析與 AI 分頁的按鈕綁定\n",
        "    # 點擊分析按鈕時，呼叫 perform_analysis_and_ai，將結果更新到對應的介面區域\n",
        "    btn_analyze.click(\n",
        "        perform_analysis_and_ai,\n",
        "        inputs=[data_source_radio, input_col_name, analysis_topk, analysis_min_df], # 注意這裡 input_col_name 是從介面讀取的值\n",
        "        outputs=[msg_analyze, grid_terms, out_analysis_report, out_ai_insights, out_ai_conclusion] # 將所有輸出綁定到介面元件\n",
        "    )\n",
        "\n",
        "\n",
        "# 啟動 Gradio 介面\n",
        "demo.launch(debug=True) # debug=True 可以看到更多執行細節"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://eb6cafdeda94d36da5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://eb6cafdeda94d36da5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ 工作表 'ptt_movie_posts' 為空或無法讀取 DataFrame。\n",
            "嘗試將 47 筆資料寫入工作表 'ptt_movie_posts'...\n",
            "✅ 已將 47 筆資料寫入工作表 'ptt_movie_posts'。\n",
            "✅ 從工作表 'ptt_movie_posts' 讀取 47 筆資料。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘗試將 50 筆資料寫入工作表 '分析結果'...\n",
            "✅ 已將 50 筆資料寫入工作表 '分析結果'。\n"
          ]
        }
      ]
    }
  ]
}